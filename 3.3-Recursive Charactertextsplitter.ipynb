{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content=\"Today, I want to highlight a crucial element in the success of machine learning \\napplications: data ingestion, particularly within the LangChain framework.\\n\\nData ingestion is the foundation that enables our language models to thrive. \\nIt involves the systematic collection and preparation of data from various sources, ensuring that our models receive high-quality, relevant information. \\nIn the context of LangChain, this process is vital for transforming raw data into actionable insights.\\n\\nWhy is data ingestion so important? First, the quality of the data directly influences the model's performance. \\nBy providing diverse and accurate datasets, we empower our models to generate meaningful responses and understand context effectively. \\nFurthermore, as we scale our applications, efficient data ingestion becomes essential. LangChain offers robust tools and integrations to simplify this process, allowing developers to automate data flows seamlessly.\\n\\nIn conclusion, prioritizing effective data ingestion not only enhances the capabilities of our language models but also leads to more impactful applications. \\nBy leveraging the tools available in LangChain, we can unlock the full potential of our data and deliver exceptional user experiences.\")]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TextLoader\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader('speech.txt')\n",
    "docs=loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 155, which is longer than the specified 100\n",
      "Created a chunk of size 334, which is longer than the specified 100\n",
      "Created a chunk of size 463, which is longer than the specified 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content='Today, I want to highlight a crucial element in the success of machine learning \\napplications: data ingestion, particularly within the LangChain framework.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='Data ingestion is the foundation that enables our language models to thrive. \\nIt involves the systematic collection and preparation of data from various sources, ensuring that our models receive high-quality, relevant information. \\nIn the context of LangChain, this process is vital for transforming raw data into actionable insights.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content=\"Why is data ingestion so important? First, the quality of the data directly influences the model's performance. \\nBy providing diverse and accurate datasets, we empower our models to generate meaningful responses and understand context effectively. \\nFurthermore, as we scale our applications, efficient data ingestion becomes essential. LangChain offers robust tools and integrations to simplify this process, allowing developers to automate data flows seamlessly.\"),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='In conclusion, prioritizing effective data ingestion not only enhances the capabilities of our language models but also leads to more impactful applications. \\nBy leveraging the tools available in LangChain, we can unlock the full potential of our data and deliver exceptional user experiences.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "text_splitter= CharacterTextSplitter(separator=\"\\n\\n\",chunk_size=100,chunk_overlap=20)\n",
    "text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 155, which is longer than the specified 100\n",
      "Created a chunk of size 334, which is longer than the specified 100\n",
      "Created a chunk of size 463, which is longer than the specified 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Today, I want to highlight a crucial element in the success of machine learning \n",
      "applications: data ingestion, particularly within the LangChain framework.'\n",
      "page_content='Data ingestion is the foundation that enables our language models to thrive. \n",
      "It involves the systematic collection and preparation of data from various sources, ensuring that our models receive high-quality, relevant information. \n",
      "In the context of LangChain, this process is vital for transforming raw data into actionable insights.'\n"
     ]
    }
   ],
   "source": [
    "speech=\"\"\n",
    "with open(\"speech.txt\") as f:\n",
    "    speech=f.read()\n",
    "\n",
    "text_splitter=CharacterTextSplitter(chunk_size=100,chunk_overlap=20)\n",
    "text=text_splitter.create_documents([speech])\n",
    "print(text[0])\n",
    "print(text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
